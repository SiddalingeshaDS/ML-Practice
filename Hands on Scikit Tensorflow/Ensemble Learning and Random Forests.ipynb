{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import make_moons\n",
    "\n",
    "X, y = make_moons(n_samples=500, noise=0.30, random_state=42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('lr', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)), ('rf', RandomFor...bf',\n",
       "  max_iter=-1, probability=True, random_state=42, shrinking=True,\n",
       "  tol=0.001, verbose=False))],\n",
       "         flatten_transform=None, n_jobs=1, voting='soft', weights=None)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Voting Classifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "log_clf = LogisticRegression(random_state=42)\n",
    "rnd_clf = RandomForestClassifier(random_state=42)\n",
    "svm_clf = SVC(random_state=42, probability=True)\n",
    "\n",
    "voting_clf = VotingClassifier(\n",
    "    estimators=[('lr', log_clf), ('rf', rnd_clf), ('svc', svm_clf)],\n",
    "    voting='soft')\n",
    "voting_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression 0.864\n",
      "RandomForestClassifier 0.872\n",
      "SVC 0.888\n",
      "VotingClassifier 0.912\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sid\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "for clf in (log_clf, rnd_clf, svm_clf, voting_clf):\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    print(clf.__class__.__name__, accuracy_score(y_test, y_pred))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Bagging\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "bag_clf = BaggingClassifier(\n",
    "    DecisionTreeClassifier(), n_estimators=500,\n",
    "    max_samples=100, bootstrap=True, n_jobs=-1)\n",
    "bag_clf.fit(X_train, y_train)\n",
    "y_pred = bag_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9013333333333333"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Out of bag evaluation\n",
    "bag_clf = BaggingClassifier(\n",
    "    DecisionTreeClassifier(random_state=42), n_estimators=500,\n",
    "    bootstrap=True, n_jobs=-1, oob_score=True)\n",
    "bag_clf.fit(X_train, y_train)\n",
    "bag_clf.oob_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.904"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "y_pred = bag_clf.predict(X_test)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.40291262, 0.59708738],\n",
       "       [0.3655914 , 0.6344086 ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.11111111, 0.88888889],\n",
       "       [0.37714286, 0.62285714],\n",
       "       [0.03448276, 0.96551724],\n",
       "       [0.99481865, 0.00518135],\n",
       "       [0.96825397, 0.03174603],\n",
       "       [0.77272727, 0.22727273],\n",
       "       [0.005     , 0.995     ],\n",
       "       [0.8       , 0.2       ],\n",
       "       [0.79792746, 0.20207254],\n",
       "       [0.96132597, 0.03867403],\n",
       "       [0.06214689, 0.93785311],\n",
       "       [0.        , 1.        ],\n",
       "       [0.98913043, 0.01086957],\n",
       "       [0.96470588, 0.03529412],\n",
       "       [0.99401198, 0.00598802],\n",
       "       [0.02427184, 0.97572816],\n",
       "       [0.34319527, 0.65680473],\n",
       "       [0.87777778, 0.12222222],\n",
       "       [1.        , 0.        ],\n",
       "       [0.96195652, 0.03804348],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.62903226, 0.37096774],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.16477273, 0.83522727],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.32142857, 0.67857143],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.17460317, 0.82539683],\n",
       "       [0.33333333, 0.66666667],\n",
       "       [1.        , 0.        ],\n",
       "       [0.99465241, 0.00534759],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.01578947, 0.98421053],\n",
       "       [1.        , 0.        ],\n",
       "       [0.00552486, 0.99447514],\n",
       "       [0.97311828, 0.02688172],\n",
       "       [0.90449438, 0.09550562],\n",
       "       [0.99450549, 0.00549451],\n",
       "       [0.97790055, 0.02209945],\n",
       "       [0.        , 1.        ],\n",
       "       [0.06878307, 0.93121693],\n",
       "       [1.        , 0.        ],\n",
       "       [0.0060241 , 0.9939759 ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.01149425, 0.98850575],\n",
       "       [1.        , 0.        ],\n",
       "       [0.78534031, 0.21465969],\n",
       "       [0.3908046 , 0.6091954 ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.67597765, 0.32402235],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.8       , 0.2       ],\n",
       "       [0.99431818, 0.00568182],\n",
       "       [0.62566845, 0.37433155],\n",
       "       [0.09782609, 0.90217391],\n",
       "       [0.65104167, 0.34895833],\n",
       "       [0.82857143, 0.17142857],\n",
       "       [0.        , 1.        ],\n",
       "       [0.17877095, 0.82122905],\n",
       "       [0.88205128, 0.11794872],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.99428571, 0.00571429],\n",
       "       [0.        , 1.        ],\n",
       "       [0.01685393, 0.98314607],\n",
       "       [0.02673797, 0.97326203],\n",
       "       [0.3027027 , 0.6972973 ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.8254717 , 0.1745283 ],\n",
       "       [0.01092896, 0.98907104],\n",
       "       [0.        , 1.        ],\n",
       "       [0.00561798, 0.99438202],\n",
       "       [0.2247191 , 0.7752809 ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.93650794, 0.06349206],\n",
       "       [0.84782609, 0.15217391],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.18579235, 0.81420765],\n",
       "       [0.67317073, 0.32682927],\n",
       "       [0.        , 1.        ],\n",
       "       [0.01877934, 0.98122066],\n",
       "       [0.40571429, 0.59428571],\n",
       "       [1.        , 0.        ],\n",
       "       [0.01875   , 0.98125   ],\n",
       "       [0.99441341, 0.00558659],\n",
       "       [0.22043011, 0.77956989],\n",
       "       [0.48      , 0.52      ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.01117318, 0.98882682],\n",
       "       [0.984375  , 0.015625  ],\n",
       "       [0.21764706, 0.78235294],\n",
       "       [0.89784946, 0.10215054],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.79166667, 0.20833333],\n",
       "       [1.        , 0.        ],\n",
       "       [0.00510204, 0.99489796],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.98930481, 0.01069519],\n",
       "       [0.99462366, 0.00537634],\n",
       "       [0.        , 1.        ],\n",
       "       [0.93865031, 0.06134969],\n",
       "       [0.99428571, 0.00571429],\n",
       "       [0.00505051, 0.99494949],\n",
       "       [0.22222222, 0.77777778],\n",
       "       [0.95180723, 0.04819277],\n",
       "       [0.20606061, 0.79393939],\n",
       "       [0.98333333, 0.01666667],\n",
       "       [0.        , 1.        ],\n",
       "       [0.00518135, 0.99481865],\n",
       "       [0.67553191, 0.32446809],\n",
       "       [0.34848485, 0.65151515],\n",
       "       [0.47643979, 0.52356021],\n",
       "       [0.89017341, 0.10982659],\n",
       "       [0.91052632, 0.08947368],\n",
       "       [0.03825137, 0.96174863],\n",
       "       [0.8       , 0.2       ],\n",
       "       [0.00558659, 0.99441341],\n",
       "       [0.        , 1.        ],\n",
       "       [0.02020202, 0.97979798],\n",
       "       [0.98492462, 0.01507538],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.00510204, 0.99489796],\n",
       "       [0.        , 1.        ],\n",
       "       [0.02173913, 0.97826087],\n",
       "       [0.01142857, 0.98857143],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.95882353, 0.04117647],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.35789474, 0.64210526],\n",
       "       [0.26404494, 0.73595506],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.28415301, 0.71584699],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.005     , 0.995     ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.98      , 0.02      ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.00497512, 0.99502488],\n",
       "       [0.64397906, 0.35602094],\n",
       "       [0.92      , 0.08      ],\n",
       "       [0.00507614, 0.99492386],\n",
       "       [0.98850575, 0.01149425],\n",
       "       [0.98421053, 0.01578947],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.05988024, 0.94011976],\n",
       "       [1.        , 0.        ],\n",
       "       [0.0505618 , 0.9494382 ],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.03508772, 0.96491228],\n",
       "       [0.99456522, 0.00543478],\n",
       "       [0.93209877, 0.06790123],\n",
       "       [0.74033149, 0.25966851],\n",
       "       [0.63874346, 0.36125654],\n",
       "       [0.        , 1.        ],\n",
       "       [0.1627907 , 0.8372093 ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.94300518, 0.05699482],\n",
       "       [0.97297297, 0.02702703],\n",
       "       [0.99438202, 0.00561798],\n",
       "       [0.01111111, 0.98888889],\n",
       "       [0.        , 1.        ],\n",
       "       [0.36612022, 0.63387978],\n",
       "       [0.84771574, 0.15228426],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.00543478, 0.99456522],\n",
       "       [0.        , 1.        ],\n",
       "       [0.96551724, 0.03448276],\n",
       "       [0.        , 1.        ],\n",
       "       [0.2745098 , 0.7254902 ],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.98342541, 0.01657459],\n",
       "       [0.8079096 , 0.1920904 ],\n",
       "       [0.99481865, 0.00518135],\n",
       "       [0.00549451, 0.99450549],\n",
       "       [0.08421053, 0.91578947],\n",
       "       [0.995     , 0.005     ],\n",
       "       [0.03296703, 0.96703297],\n",
       "       [0.        , 1.        ],\n",
       "       [0.04568528, 0.95431472],\n",
       "       [0.99441341, 0.00558659],\n",
       "       [0.79144385, 0.20855615],\n",
       "       [0.        , 1.        ],\n",
       "       [0.87244898, 0.12755102],\n",
       "       [0.98895028, 0.01104972],\n",
       "       [0.22159091, 0.77840909],\n",
       "       [0.18592965, 0.81407035],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.19337017, 0.80662983],\n",
       "       [0.95721925, 0.04278075],\n",
       "       [0.01092896, 0.98907104],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.51955307, 0.48044693],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.10382514, 0.89617486],\n",
       "       [0.08839779, 0.91160221],\n",
       "       [0.98918919, 0.01081081],\n",
       "       [0.02116402, 0.97883598],\n",
       "       [1.        , 0.        ],\n",
       "       [0.42134831, 0.57865169],\n",
       "       [0.09090909, 0.90909091],\n",
       "       [0.54123711, 0.45876289],\n",
       "       [0.62903226, 0.37096774],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.56216216, 0.43783784],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.24571429, 0.75428571],\n",
       "       [0.82386364, 0.17613636],\n",
       "       [0.06557377, 0.93442623],\n",
       "       [1.        , 0.        ],\n",
       "       [0.77472527, 0.22527473],\n",
       "       [0.        , 1.        ],\n",
       "       [0.00540541, 0.99459459],\n",
       "       [0.07777778, 0.92222222],\n",
       "       [0.04494382, 0.95505618],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.87700535, 0.12299465],\n",
       "       [0.18090452, 0.81909548],\n",
       "       [0.94059406, 0.05940594],\n",
       "       [0.01015228, 0.98984772],\n",
       "       [0.59042553, 0.40957447],\n",
       "       [0.03846154, 0.96153846],\n",
       "       [0.98830409, 0.01169591],\n",
       "       [0.82758621, 0.17241379],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.97029703, 0.02970297],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.30337079, 0.69662921],\n",
       "       [0.98882682, 0.01117318],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.005     , 0.995     ],\n",
       "       [0.86263736, 0.13736264],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.74731183, 0.25268817],\n",
       "       [0.92307692, 0.07692308],\n",
       "       [1.        , 0.        ],\n",
       "       [0.73595506, 0.26404494],\n",
       "       [0.45555556, 0.54444444],\n",
       "       [0.        , 1.        ],\n",
       "       [0.91712707, 0.08287293],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.8547486 , 0.1452514 ],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.76262626, 0.23737374],\n",
       "       [0.10144928, 0.89855072],\n",
       "       [0.5359116 , 0.4640884 ],\n",
       "       [0.24193548, 0.75806452],\n",
       "       [0.        , 1.        ],\n",
       "       [0.86170213, 0.13829787],\n",
       "       [0.84705882, 0.15294118],\n",
       "       [0.00502513, 0.99497487],\n",
       "       [1.        , 0.        ],\n",
       "       [0.99438202, 0.00561798],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.01136364, 0.98863636],\n",
       "       [0.96969697, 0.03030303],\n",
       "       [0.95      , 0.05      ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.50847458, 0.49152542],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.97435897, 0.02564103],\n",
       "       [0.04545455, 0.95454545],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.984375  , 0.015625  ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.1       , 0.9       ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.99465241, 0.00534759],\n",
       "       [0.01515152, 0.98484848],\n",
       "       [1.        , 0.        ],\n",
       "       [0.09693878, 0.90306122],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.40669856, 0.59330144],\n",
       "       [0.08045977, 0.91954023],\n",
       "       [0.22222222, 0.77777778],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.23333333, 0.76666667],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.95135135, 0.04864865],\n",
       "       [0.31707317, 0.68292683],\n",
       "       [0.99404762, 0.00595238],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.99401198, 0.00598802],\n",
       "       [0.        , 1.        ],\n",
       "       [0.02247191, 0.97752809],\n",
       "       [0.99441341, 0.00558659],\n",
       "       [1.        , 0.        ],\n",
       "       [0.01970443, 0.98029557],\n",
       "       [0.70121951, 0.29878049]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bag_clf.oob_decision_function_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rnd_clf = RandomForestClassifier(n_estimators=500, max_leaf_nodes=16, n_jobs=-1)\n",
    "rnd_clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred_rf = rnd_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sepal length (cm) 0.10343645337251296\n",
      "sepal width (cm) 0.02521255549246823\n",
      "petal length (cm) 0.45944342355278334\n",
      "petal width (cm) 0.4119075675822359\n"
     ]
    }
   ],
   "source": [
    "# feature importance\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "iris = load_iris()\n",
    "rnd_clf = RandomForestClassifier(n_estimators=500, n_jobs=-1)\n",
    "rnd_clf.fit(iris[\"data\"], iris[\"target\"])\n",
    "for name, score in zip(iris[\"feature_names\"], rnd_clf.feature_importances_):\n",
    "    print(name, score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(algorithm='SAMME.R',\n",
       "          base_estimator=DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=1,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best'),\n",
       "          learning_rate=0.5, n_estimators=200, random_state=None)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ada Boost Classifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "ada_clf = AdaBoostClassifier(\n",
    "    DecisionTreeClassifier(max_depth=1), n_estimators=200,\n",
    "    algorithm =\"SAMME.R\", learning_rate=0.5)\n",
    "ada_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(criterion='mse', max_depth=2, max_features=None,\n",
       "           max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "           min_impurity_split=None, min_samples_leaf=1,\n",
       "           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "           presort=False, random_state=None, splitter='best')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Gradient Tree Boosting or Gradient Booseted Regression Trees\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "tree_reg1 = DecisionTreeRegressor(max_depth=2)\n",
    "tree_reg1.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(criterion='mse', max_depth=2, max_features=None,\n",
       "           max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "           min_impurity_split=None, min_samples_leaf=1,\n",
       "           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "           presort=False, random_state=None, splitter='best')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y2 = y - tree_reg1.predict(X)\n",
    "tree_reg2 = DecisionTreeRegressor(max_depth=2)\n",
    "tree_reg2.fit(X, y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(criterion='mse', max_depth=2, max_features=None,\n",
       "           max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "           min_impurity_split=None, min_samples_leaf=1,\n",
       "           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "           presort=False, random_state=None, splitter='best')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y3 = y2 - tree_reg2.predict(X)\n",
    "tree_reg3 = DecisionTreeRegressor(max_depth=2)\n",
    "tree_reg3.fit(X, y3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_pred = sum(tree.predict(X_test) for tree in (tree_reg1, tree_reg2, tree_reg3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,\n",
       "             learning_rate=1.0, loss='ls', max_depth=2, max_features=None,\n",
       "             max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "             min_impurity_split=None, min_samples_leaf=1,\n",
       "             min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "             n_estimators=3, presort='auto', random_state=None,\n",
       "             subsample=1.0, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "gbrt = GradientBoostingRegressor(max_depth=2, n_estimators=3, learning_rate=1.0)\n",
    "gbrt.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,\n",
       "             learning_rate=0.1, loss='ls', max_depth=2, max_features=None,\n",
       "             max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "             min_impurity_split=None, min_samples_leaf=1,\n",
       "             min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "             n_estimators=56, presort='auto', random_state=None,\n",
       "             subsample=1.0, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Finding the best number of trees\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y)\n",
    "\n",
    "gbrt = GradientBoostingRegressor(max_depth=2, n_estimators=120)\n",
    "gbrt.fit(X_train, y_train)\n",
    "\n",
    "errors = [mean_squared_error(y_val, y_pred) for y_pred in gbrt.staged_predict(X_val)]\n",
    "bst_n_estimators = np.argmin(errors)\n",
    "\n",
    "gbrt_best = GradientBoostingRegressor(max_depth=2, n_estimators=bst_n_estimators)\n",
    "gbrt_best.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Early stopping\n",
    "gbrt = GradientBoostingRegressor(max_depth=2, warm_start=True)\n",
    "\n",
    "min_val_error = float(\"inf\")\n",
    "error_going_up = 0\n",
    "for n_estimators in range(1, 120):\n",
    "    gbrt.n_estimators = n_estimators\n",
    "    gbrt.fit(X_train, y_train)\n",
    "    y_pred = gbrt.predict(X_val)\n",
    "    val_error = mean_squared_error(y_val, y_pred)\n",
    "    if val_error < min_val_error:\n",
    "        val_error = min_val_error\n",
    "        error_going_up = 0\n",
    "    else:\n",
    "        error_going_up += 1\n",
    "        if error_going_up == 5:\n",
    "            break # early stopping"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
